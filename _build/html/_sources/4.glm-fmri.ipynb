{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aad1f2c-ba86-4cc5-a20d-f805a6f985a3",
   "metadata": {},
   "source": [
    "# Using the GLM to Model fMRI Data\n",
    "We have now seen how to use the GLM as a tool to analyse non-imaging data. The next challenge is to take what we have learned and apply it to fMRI data. Remember, from previous lessons, that the primary data of interest is the fMRI time-series at each voxel. In the context of the GLM, the time-series from a single voxel forms the outcome vector $\\mathbf{y}$. The approach is then to loop through every voxel in the image, estimating the GLM for each time-series separately. This is known as the *mass-univariate* framework.\n",
    "\n",
    "## The Mass-univariate Framework\n",
    "The mass-univariate approach to modelling fMRI data was first introduced by [Fristion *et al.* (1994)](https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.460020402). In brief, we build a *single* design matrix $\\mathbf{X}$ of predictors that code for changes in signal based on the timing of the experimental stimuli. We then use $\\mathbf{X}$ to estimate the GLM at each voxel separately. For voxel $\\nu$, the model is therefore\n",
    "\n",
    "$$\n",
    "\\mathbf{y}_{\\nu} = \\mathbf{X}\\boldsymbol{\\beta}_{\\nu} + \\boldsymbol{\\epsilon}_{\\nu}\n",
    "$$\n",
    "\n",
    "Notice that the outcome variable $\\left(\\mathbf{y}_{\\nu}\\right)$, parameters $\\left(\\boldsymbol{\\beta}_{\\nu}\\right)$ and errors $\\left(\\boldsymbol{\\epsilon}_{\\nu}\\right)$ are unique to voxel $\\nu$, but that the design matrix $\\left(\\mathbf{X}\\right)$ is the *same* across all voxels. After fitting the model at every voxel, we will have as many $\\boldsymbol{\\beta}$ vectors and $\\boldsymbol{\\epsilon}$ vectors as there are voxels. These values can be saved to images, as illustrated in {numref}`param-img-fig`.\n",
    "\n",
    "```{figure} images/param-images.png\n",
    "---\n",
    "width: 800px\n",
    "name: param-img-fig\n",
    "---\n",
    "Illustration of how the parameter estimates from a mass-univariate GLM can be saved to images.\n",
    "```\n",
    "\n",
    "Thinking back to how we interpret the GLM parameters, an image of estimates associated with a *continuous* predictor variable will indicate the magnitude of a *regression slope* at each voxel. Similarly, an image of estimates associated with a *categorical* predictor variable will indicate the magnitude of a *mean difference* at each voxel. In both cases, brighter voxels mean larger estimates and darker voxels mean smaller estimates. Importantly, because these estimates can be positive or negative, those regions that are *darkest* or *brightest* are of most interest. Even before performing any sort of inferential procedure, notice how these images show interesting regional effects associated with the predictor variables.\n",
    "\n",
    "## Creating Predictors for the Time Series\n",
    "As indicated above, the mass-univariate approach depends upon forming a single design matrix that can be used at each voxel to predict changes in the BOLD signal associated with the experimental stimuli. The easiest approach to code such changes is to specify a dummy variable, where a value of 1 indicates the presence of an experimental stimulus and a value of 0 indicates its absence. To make this clear, imagine a simple finger tapping experiment where the subject taps their fingers for 5 seconds and then rests for 5 seconds. To code this pattern as a dummy variable, we use a value of 0 to represent periods of rest and a value of 1 to indicate periods of tapping. Any region of the brain that follows this on-off pattern is assumed to be involved in the action of finger tapping. For instance, consider the illustration in {numref}`timeseries-dummy-fig`. This shows a time-series from the motor cortex on the left and a dummy variable for the tapping conditions on the right.\n",
    "\n",
    "```{figure} images/time-series-and-dummy.png\n",
    "---\n",
    "width: 800px\n",
    "name: timeseries-dummy-fig\n",
    "---\n",
    "Illustration of how a dummy variable can code the on-off pattern of the stimulus presentation.\n",
    "```\n",
    "\n",
    "In terms of the GLM, the design matrix for this form of model would contains a columns of 1's for the intercept and then a dummy variable coding which elements of the time-series were measured during rest, and which elements were measured during tapping. For instance, if the subject repeated the 5 seconds of tapping twice and we used TR = 1, the model would have the form\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "y_{1}  \\\\\n",
    "y_{2}  \\\\\n",
    "y_{3}  \\\\\n",
    "y_{4}  \\\\\n",
    "y_{5}  \\\\\n",
    "y_{6}  \\\\\n",
    "y_{7}  \\\\\n",
    "y_{8}  \\\\\n",
    "y_{9}  \\\\\n",
    "y_{10} \\\\\n",
    "y_{11} \\\\\n",
    "y_{12} \\\\\n",
    "y_{13} \\\\\n",
    "y_{14} \\\\\n",
    "y_{15} \\\\\n",
    "y_{16} \\\\\n",
    "y_{17} \\\\\n",
    "y_{18} \\\\\n",
    "y_{19} \\\\\n",
    "y_{20}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "1 & 0 \\\\\n",
    "1 & 0 \\\\\n",
    "1 & 0 \\\\\n",
    "1 & 0 \\\\\n",
    "1 & 1 \\\\\n",
    "1 & 1 \\\\\n",
    "1 & 1 \\\\\n",
    "1 & 1 \\\\\n",
    "1 & 1 \\\\\n",
    "1 & 0 \\\\\n",
    "1 & 0 \\\\\n",
    "1 & 0 \\\\\n",
    "1 & 0 \\\\\n",
    "1 & 0 \\\\\n",
    "1 & 1 \\\\\n",
    "1 & 1 \\\\\n",
    "1 & 1 \\\\\n",
    "1 & 1 \\\\\n",
    "1 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\beta_{0} \\\\\n",
    "\\beta_{1}\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "\\epsilon_{1}  \\\\\n",
    "\\epsilon_{2}  \\\\\n",
    "\\epsilon_{3}  \\\\\n",
    "\\epsilon_{4}  \\\\\n",
    "\\epsilon_{5}  \\\\\n",
    "\\epsilon_{6}  \\\\\n",
    "\\epsilon_{7}  \\\\\n",
    "\\epsilon_{8}  \\\\\n",
    "\\epsilon_{9}  \\\\\n",
    "\\epsilon_{10} \\\\\n",
    "\\epsilon_{11} \\\\\n",
    "\\epsilon_{12} \\\\\n",
    "\\epsilon_{13} \\\\\n",
    "\\epsilon_{14} \\\\\n",
    "\\epsilon_{15} \\\\\n",
    "\\epsilon_{16} \\\\\n",
    "\\epsilon_{17} \\\\\n",
    "\\epsilon_{18} \\\\\n",
    "\\epsilon_{19} \\\\\n",
    "\\epsilon_{20}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "In terms of interpreting the parameters, we know that a dummy variable will produce a parameter estimate that can be interpreted as the *mean difference* between the categories. When applied to fMRI data, the parameter estimate will tell us the average difference in the BOLD signal between the rest condition and the tapping conditions. The image of estimates for $\\beta_{1}$ will therefore indicate where in the brain the largest signal change occurred between rest and tapping. The value of $\\beta_{0}$ will therefore be the average signal during the rest condition, with the average value of the BOLD signal during the tapping condition given by $\\beta_{0} + \\beta_{1}$. This is illustrated in {numref}`dummy-interp-fig`.\n",
    "\n",
    "```{figure} images/dummy-interp.png\n",
    "---\n",
    "width: 550px\n",
    "name: dummy-interp-fig\n",
    "---\n",
    "Illustration of interpreting the parameter values from a dummy variable model.\n",
    "```\n",
    "\n",
    "```{important}\n",
    "If you do not understand where this interpretation of the dummy variable parameters comes from, go back to the explanation of dummy variables from earlier in this lesson. It is very important that this is understood to allow for accurate interpretation of fMRI results.\n",
    "```\n",
    "\n",
    "## Visualising the Design Matrix\n",
    "As already indicated, the design matrix is a very important part of the GLM. Not only is it the only element of the GLM equation that is constant across voxels, but it also encodes our predictions about what we expect to see in regions of the brain that are responding to the experimental manipulation. Knowing the structure of the design matrix is therefore essential to being able to interpret the parameter estimates. Because of this, SPM take the unique step of *drawing* the design matrix as a means of summarising the model. An example of this is given in {numref}`X-example-fig`. Solid blocks of colour represent dummy variables whereas those columns with a gradient represent continuous variables.\n",
    "\n",
    "```{figure} images/X-example.jpg\n",
    "---\n",
    "width: 700px\n",
    "name: X-example-fig\n",
    "---\n",
    "Example of the design matrix visualisation produced by SPM.\n",
    "```\n",
    "\n",
    "We can create a similar visualisation by using the `imagesc` function in MATLAB with the design matrix from the previous example. To make sure all the columns are visible (irrespective of their scale), we use the `spm_DesMtx()` function to scale the design matrix for visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07bd0235-2b9c-42ff-934c-430bebbdbfe4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xi = [1     1     1     1     1     1;     ...\n",
    "      110   110   93    110   175   105;   ...\n",
    "      2.620 2.875 2.320 3.215 3.440 3.460; ...\n",
    "      1     1     1     0     0     0]';\n",
    "\n",
    "X_scaled = spm_DesMtx('Sca',Xi); % scale for visualisation\n",
    "imagesc(X_scaled); \n",
    "colormap('gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b3c7b1-6357-41b4-8305-356b9376ebea",
   "metadata": {},
   "source": [
    "```{admonition} Advanced: Time-series and Regression Perspectives\n",
    ":class: dropdown\n",
    "Compared to when we were applying the GLM to non-imaging data, one of the additional complications of time series data is that it has a natural ordering based upon when each data point was collected. This means there are *two* complimentary perspectives we can use for understanding the model. In the *time-series perspective*, we view the data in its natural ordering with time on the $x$-axis and intensity on the $y$-axis. From this perspective, we can see gross changes in the shape of the signal over time. Superimposing the model prediction allows visualising of when the predicted signal change corresponds to a change in the raw data. This is shown in the *left* column of {numref}`ts-reg-fig`. As an alternative, the *regression perspective* involves visualising the model as a typical multiple regression problem. When plotted, the value of the predictor variable is given on the $x$-axis, with intensity on the $y$-axis. For a dummy variable, the $x$-axis will correspond to values of only 1 or 0, resulting in a bisection of the data into those values measured during one experimental condition and those measured during the other. From this perspective, superimposing the model prediction means drawing the regression line between the two categories of data, as shown in the *right* column of {numref}`ts-reg-fig`.\n",
    "\n",
    "```{figure} images/ts-reg-persp.png\n",
    "---\n",
    "width: 800px\n",
    "name: ts-reg-fig\n",
    "---\n",
    "Example of both the time series perspective (*left*) and regression perspective (*right*) on the model fit from the GLM. This is shown for both a voxel with a strong signal change (*top*) and a voxel with a weak signal change (*bottom*). As we can see, the magnitude of the regression slope corresponds to the magnitude of signal change from one condition to another. In the time series perspective, this can be seen as the *height* of the signal change during periods associated with each condition.\n",
    "```\n",
    "\n",
    "## Inference\n",
    "At this point, it would be natural to try implementing the same inferential procedure we saw earlier, using the mass-univariate framework. This would involve converting each parameter estimate to a *t*-statistic by dividing by its respective standard error. This would produce several *images* of *t*-statistics and associated *p*-values, allowing us to discern which voxels are associated with significant effects. Unfortunately, there are a number of complications with this approach that are beyond the scope of this lesson. As such, we will be leaving the process of statistical inference using images until next week. Furthermore, there are a number of issues with the methods outlined in this section that require correction before we can consider performing inference on the results of the mass-univariate GLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa551df-7cd1-4b2c-a927-c6dc14c5ae6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MATLAB Kernel",
   "language": "matlab",
   "name": "jupyter_matlab_kernel"
  },
  "language_info": {
   "file_extension": ".m",
   "mimetype": "text/x-matlab",
   "name": "matlab"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
