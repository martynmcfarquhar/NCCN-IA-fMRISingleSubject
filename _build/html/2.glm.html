

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>The General Linear Model &#8212; fMRI Single-subject Statistical Modelling</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.4cbf315f70debaebd550c87a6162cf0f.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '2.glm';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="The GLM: A Worked Example" href="3.glm-example.html" />
    <link rel="prev" title="The Need for Statistical Modelling" href="1.need-for-modelling.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="0.intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="fMRI Single-subject Statistical Modelling - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="fMRI Single-subject Statistical Modelling - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="0.intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1.need-for-modelling.html">The Need for Statistical Modelling</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">The General Linear Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="3.glm-example.html">The GLM: A Worked Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.glm-fmri.html">Using the GLM to Model fMRI Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="5.glm-fmri-problems.html">Problems With Using the GLM to Model fMRI Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="6.single-subject-spm.html">Single-subject Modelling in SPM</a></li>
<li class="toctree-l1"><a class="reference internal" href="7.summary-quiz.html">Summary and Quiz</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/martynmcfarquhar/NCCN-IA-fMRIPreProcessing" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/martynmcfarquhar/NCCN-IA-fMRIPreProcessing/issues/new?title=Issue%20on%20page%20%2F2.glm.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/2.glm.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>The General Linear Model</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-general-linear-model-framework">The General Linear Model Framework</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-regression">Simple Regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-regression">Multiple Regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-regression-in-matrix-form">Multiple Regression in Matrix Form</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-the-design-matrix">Building the Design Matrix</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#continuous-predictor-variables">Continuous Predictor Variables</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#categorical-predictor-variables">Categorical Predictor Variables</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-the-parameters">Estimating the Parameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-the-parameters">Interpreting the Parameters</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parameter-estimates-for-continuous-predictors">Parameter Estimates for Continuous Predictors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parameter-estimates-for-categorical-predictors">Parameter Estimates for Categorical Predictors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#standard-errors-of-the-estimates">Standard Errors of the Estimates</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inference">Inference</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="the-general-linear-model">
<h1>The General Linear Model<a class="headerlink" href="#the-general-linear-model" title="Permalink to this heading">#</a></h1>
<p>To begin with, we will take a high-level perspective on the GLM as a <em>framework</em> that can be applied to any dataset. This may appear somewhat abstract on a first read, however, we will see how this is applied to a real dataset in the next section. At this point, we are not talking about fMRI data specifically. Given that this is a specialised application of the GLM, we first need to discuss the general theory before seeing how it can be applied to neuroimaging data.</p>
<section id="the-general-linear-model-framework">
<h2>The General Linear Model Framework<a class="headerlink" href="#the-general-linear-model-framework" title="Permalink to this heading">#</a></h2>
<p>To begin with, we will discuss the mathematical framework behind the GLM. In order to understand the GLM, we need to understand <em>multiple regression</em> which, in its most basic form, is know as <em>simple</em> regression.</p>
<section id="simple-regression">
<h3>Simple Regression<a class="headerlink" href="#simple-regression" title="Permalink to this heading">#</a></h3>
<p>In a simple regression model there is a single outcome variable <span class="math notranslate nohighlight">\(y\)</span> that is associated with a single predictor variable <span class="math notranslate nohighlight">\(x\)</span>. The simple regression model takes the form</p>
<div class="math notranslate nohighlight">
\[
y_{i} = \beta_{0} + \beta_{1}x_{i} + \epsilon_{i}
\]</div>
<p>which defines a straight-line fit to the data, where <span class="math notranslate nohighlight">\(\beta_{0}\)</span> representing the <em>intercept</em> and <span class="math notranslate nohighlight">\(\beta_{1}\)</span> representing the <em>slope</em>. The term <span class="math notranslate nohighlight">\(\epsilon\)</span> quantifies the amount of <em>error</em> in the model, allowing for the fact that a perfect fit between the two variables is rarely possible. This model is illustrated in <a class="reference internal" href="#simple-fig"><span class="std std-numref">Fig. 4</span></a>. In this example, the manager of a building company wants a good estimate of the required number of hours to build given the size of the lot.</p>
<figure class="align-default" id="simple-fig">
<a class="reference internal image-reference" href="_images/simple-reg.png"><img alt="_images/simple-reg.png" src="_images/simple-reg.png" style="width: 700px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4 </span><span class="caption-text">Illustration of how a simple regression model amounts to constructing a straight-line to summarise the relationship between the predictor variable and the outcome variable.</span><a class="headerlink" href="#simple-fig" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>As we can see, the simple regression model consists of a straight line through the scatterplot of measurements. For each value of <code class="docutils literal notranslate"><span class="pre">Lot</span> <span class="pre">Size</span></code>, the point on the regression line represents the predicted value of <code class="docutils literal notranslate"><span class="pre">Hours</span></code>. The magnitude of the estimated slope is therefore of interest, given that this quantifies the <em>strength</em> of the general relationship between the two variables. However, we also need to consider how close the raw data sits to the regression line as data that are tightly-packed around the regression line suggest a model that fits the data well. This concept of <em>model fit</em> is therefore quantified by the <em>errors</em>. The smaller that the <span class="math notranslate nohighlight">\(\epsilon\)</span> terms are, the shorter the vertical distances between the regression line and the raw data.</p>
<p>These concepts can be further understood by considering the probability model for a simple regression</p>
<div class="math notranslate nohighlight">
\[
y_{i} \sim \mathcal{N}(\beta_{0} + \beta_{1}x_{i}, \sigma)
\]</div>
<p>Taking the example from <a class="reference internal" href="#simple-fig"><span class="std std-numref">Fig. 4</span></a>, each value of <code class="docutils literal notranslate"><span class="pre">Lot</span> <span class="pre">Size</span></code> is therefore associated with a normal distribution of values for <code class="docutils literal notranslate"><span class="pre">Hours</span></code> where the means sit along the population regression line. An illustration of this concept is given in <a class="reference internal" href="#simple-prob-fig"><span class="std std-numref">Fig. 5</span></a>.</p>
<figure class="align-default" id="simple-prob-fig">
<a class="reference internal image-reference" href="_images/simple-reg-prob.gif"><img alt="_images/simple-reg-prob.gif" src="_images/simple-reg-prob.gif" style="width: 700px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 5 </span><span class="caption-text">Illustration of the simple regression normal probability model. The operator <span class="math notranslate nohighlight">\(E(Y)\)</span> indicates the <em>expected</em> value of the outcome variable which, for a normal distribution, is equivalent to the mean.</span><a class="headerlink" href="#simple-prob-fig" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>The standard deviation of these normal distributions is given by <span class="math notranslate nohighlight">\(\sigma\)</span> and reflects how widely spread the data are around the regression line. There is therefore a direct connection between the width of the assumed probability distributions and the model errors. Remembering that this probability model represents the <em>population</em>, the aim of a simple regression analysis is to use a <em>sample</em> to estimate both the <em>mean</em> and <em>variance</em> of the population distribution. As the mean depends upon the parameters <span class="math notranslate nohighlight">\(\beta_{0}\)</span> and <span class="math notranslate nohighlight">\(\beta_{1}\)</span>, these must also be estimated from the sample. Finding the line that best fits the data will result in estimates for <span class="math notranslate nohighlight">\(\beta_{0}\)</span> and <span class="math notranslate nohighlight">\(\beta_{1}\)</span>. The errors resulting from this fit can then be used to estimate <span class="math notranslate nohighlight">\(\sigma\)</span> and the probability model is complete.</p>
<p>Once the parameters are estimated, hypothesis testing can be used to determine whether the null hypotheses</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathcal{H}_{0}:&amp; \beta_{0} = 0 \\
\mathcal{H}_{0}:&amp; \beta_{1} = 0
\end{align}
\end{split}\]</div>
<p>can be rejected. Usually, the test on <span class="math notranslate nohighlight">\(\beta_{1}\)</span> is of most interest because a slope of 0 is indicative of <em>no</em> relationship between the outcome and predictor variables. If significant, we would assume some non-zero relationship is present in the population and can interpret what the magnitude of the slope tells us about the relationship under study. This is often in the context of using the simple regression model to <em>predict</em> the outcome using the values of the predictor. For the example above, this would result in being able to predict <code class="docutils literal notranslate"><span class="pre">Hours</span></code> by only knowing the value of <code class="docutils literal notranslate"><span class="pre">Lot</span> <span class="pre">Size</span></code>, allowing the manager to determine if more or fewer workers need to be hired as production demands are scaled up or down.</p>
</section>
<section id="multiple-regression">
<h3>Multiple Regression<a class="headerlink" href="#multiple-regression" title="Permalink to this heading">#</a></h3>
<p>Expanding the simple regression model to contain <em>multiple</em> predictor variables produces the multiple regression model. As such, the multiple regression model with <span class="math notranslate nohighlight">\(k\)</span> predictor variables is given by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
y_{i} &amp;= \beta_{0} + \beta_{1}x_{i1} + \beta_{2}x_{i2} + \dots + \beta_{k}x_{ik} + \epsilon_{i} \\
&amp;= \beta_{0} + \sum_{j=1}^{k} \beta_{j}x_{ij} + \epsilon_{i},
\end{align}
\end{split}\]</div>
<p>where we usually assume a normal probability model of the form</p>
<div class="math notranslate nohighlight">
\[
y_{i} \sim \mathcal{N}\left(\beta_{0} + \sum_{j=1}^{k} \beta_{j}x_{ij},\sigma\right).
\]</div>
<p>Conceptually, much of multiple regression is the same as simple regression, except for a few details. Firstly, rather than a regression line this model estimates a regression <em>plane</em> in <span class="math notranslate nohighlight">\(k\)</span>-dimensional space. For instance, if <span class="math notranslate nohighlight">\(k=2\)</span> then the model can be visualised as shown in <a class="reference internal" href="#plane-fig"><span class="std std-numref">Fig. 6</span></a></p>
<figure class="align-default" id="plane-fig">
<a class="reference internal image-reference" href="_images/reg-plane.png"><img alt="_images/reg-plane.png" src="_images/reg-plane.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 6 </span><span class="caption-text">Illustration of how a multiple regression model with <span class="math notranslate nohighlight">\(k\)</span> predictors forms a regression <em>plane</em> through <span class="math notranslate nohighlight">\(k\)</span>-dimensional space.</span><a class="headerlink" href="#plane-fig" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>The means of the assumed normal distributions are no longer points along a regression line, rather they become points on a plane in <span class="math notranslate nohighlight">\(k\)</span>-dimensional space. The individual regression slopes for each predictor <span class="math notranslate nohighlight">\(\left(\beta_{j}\right)\)</span> are given by the <em>edges</em> of this plane (where <span class="math notranslate nohighlight">\(j = 1,\dots,k\)</span>). Importantly, these slopes are not the same as fitting a simple regression model to each predictor separately. The slope coefficients represent the effect of each predictor after taking all other predictors into account. This means that adding or altering the predictors will change <em>all</em> the parameter estimates. This is an important point because many statistical modelling decisions are built upon this fact. For instance, the notion of <em>controlling</em> for the effect of a variable is based directly upon this behaviour.</p>
<p>Despite these differences, the multiple regression model proceeds in much the same fashion as simple regression. The individual parameters of the mean function can be estimated to produce a single estimate for the intercept <span class="math notranslate nohighlight">\(\left(\beta_{0}\right)\)</span> and <span class="math notranslate nohighlight">\(k\)</span> estimates for the slopes <span class="math notranslate nohighlight">\(\left(\beta_{1},\dots,\beta_{k}\right)\)</span>. Estimation of the variance again proceeds using the errors, which now represent vertical distances from the regression <em>plane</em> to the raw data. Hypothesis tests can then be performed on each of the estimates to determine which of the <span class="math notranslate nohighlight">\(k\)</span> variables appears to show a significant non-zero relationship with the outcome. This involves testing null hypotheses of the form</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathcal{H}_{0}:&amp; \beta_{0} = 0 \\
\mathcal{H}_{0}:&amp; \beta_{1} = 0 \\
&amp;\vdots \\
\mathcal{H}_{0}:&amp; \beta_{k} = 0
\end{align}
\end{split}\]</div>
<p>Much like simple regression, the general aim is the accurate <em>prediction</em> of the outcome, this time using value of <em>multiple</em> variables. For instance, the manager of the building company may enhance their model of <code class="docutils literal notranslate"><span class="pre">Hours</span></code> by also considering <code class="docutils literal notranslate"><span class="pre">Wage</span></code> and <code class="docutils literal notranslate"><span class="pre">Age</span></code> of the workers, alongside <code class="docutils literal notranslate"><span class="pre">Lot</span> <span class="pre">Size</span></code>. This may allow for a more accurate prediction of <code class="docutils literal notranslate"><span class="pre">Hours</span></code>, as well as allowing the manager to determine which factor is the most influential and where the focus should be when considering how to adapt to changes in production.</p>
</section>
<section id="multiple-regression-in-matrix-form">
<h3>Multiple Regression in Matrix Form<a class="headerlink" href="#multiple-regression-in-matrix-form" title="Permalink to this heading">#</a></h3>
<p>Now that we have discussed both <em>simple</em> and <em>multiple</em> regression, we can return to the topic of the GLM. The most important point to understand is that the GLM is simply <em>multiple regression in matrix form</em>. As such, if you understand multiple regression, then you already understand the GLM.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If you do not feel comfortable with multiple regression at this stage, do not go any further. Spend some time reading around the subject and looking at other resources to get better acquainted with this method. Without understanding mutliple regression, everything that follows will be much harder to understand.</p>
</div>
<p>In terms of writing multiple regression in matrix notation, we start with the observation that there are always <span class="math notranslate nohighlight">\(n\)</span> regression equations, one for each data point</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
y_{1} &amp;= \beta_{0} + \beta_{1}x_{11} + \beta_{2}x_{12} + \dots + \beta_{k}x_{1k} + \epsilon_{1} \\
y_{2} &amp;= \beta_{0} + \beta_{1}x_{21} + \beta_{2}x_{22} + \dots + \beta_{k}x_{2k} + \epsilon_{2} \\
y_{3} &amp;= \beta_{0} + \beta_{1}x_{31} + \beta_{2}x_{32} + \dots + \beta_{k}x_{3k} + \epsilon_{3} \\
\vdots  \\
y_{n} &amp;= \beta_{0} + \beta_{1}x_{n1} + \beta_{2}x_{n2} + \dots + \beta_{k}x_{nk} + \epsilon_{n}
\end{align}
\end{split}\]</div>
<p>Because these regression equations represent a system of linear equations, we know we can write them as vectors and matrices. Importantly, we can separate the predictor variables from the coefficients to give the following structure</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
y_{1} \\
y_{2} \\
y_{3} \\
\vdots \\
y_{n}
\end{bmatrix}
=
\begin{bmatrix}
1      &amp; x_{11} &amp; x_{12}  &amp; \dots  &amp; x_{1k} \\
1      &amp; x_{21} &amp; x_{22}  &amp; \dots  &amp; x_{2k} \\
1      &amp; x_{31} &amp; x_{32}  &amp; \dots  &amp; x_{3k} \\
\vdots &amp; \vdots &amp; \vdots  &amp; \ddots &amp; \vdots \\
1      &amp; x_{n1} &amp; x_{n2}  &amp; \dots  &amp; x_{nk} 
\end{bmatrix}
\begin{bmatrix}
\beta_{0} \\
\beta_{1} \\
\beta_{2} \\
\vdots    \\
\beta_{k}
\end{bmatrix}
+
\begin{bmatrix}
\epsilon_{1} \\
\epsilon_{2} \\
\epsilon_{3} \\
\vdots       \\
\epsilon_{n}
\end{bmatrix}
\end{split}\]</div>
<p>This can be written in shorthand as</p>
<div class="math notranslate nohighlight">
\[
\mathbf{Y} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\epsilon}
\]</div>
<p>This is probably the most important equation you will see on this course. It encapsulates the entire structure of our data analysis and is something you will become intimately familiar with during this module. To make this structure clear</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{Y}\)</span> represents the <em>data vector</em> containing the values of the outcome variable</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{X}\)</span> represents the <em>design matrix</em> containing each of the predictor variables as columns</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> represents the vector of <em>model parameters</em></p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\epsilon}\)</span> represents the vector of <em>errors</em></p></li>
</ul>
<p>Importantly, we need to recognise how multiplying <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> recreates the <span class="math notranslate nohighlight">\(n\)</span> regression equations.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{X}\boldsymbol{\beta} = 
\begin{bmatrix}
1      &amp; x_{11} &amp; x_{12}  &amp; \dots  &amp; x_{1k} \\
1      &amp; x_{21} &amp; x_{22}  &amp; \dots  &amp; x_{2k} \\
1      &amp; x_{31} &amp; x_{32}  &amp; \dots  &amp; x_{3k} \\
\vdots &amp; \vdots &amp; \vdots  &amp; \ddots &amp; \vdots \\
1      &amp; x_{n1} &amp; x_{n2}  &amp; \dots  &amp; x_{nk} 
\end{bmatrix}
\begin{bmatrix}
\beta_{0} \\
\beta_{1} \\
\beta_{2} \\
\vdots    \\
\beta_{k}
\end{bmatrix}
=
\begin{bmatrix}
\beta_{0} + \beta_{1}x_{11} + \beta_{2}x_{12} + \dots  + \beta_{k}x_{1k} \\
\beta_{0} + \beta_{1}x_{21} + \beta_{2}x_{22} + \dots  + \beta_{k}x_{2k} \\
\beta_{0} + \beta_{1}x_{31} + \beta_{2}x_{32} + \dots  + \beta_{k}x_{3k} \\
\vdots  \\
\beta_{0} + \beta_{1}x_{n1} + \beta_{2}x_{n2} + \dots  + \beta_{k}x_{nk}
\end{bmatrix}
= \hat{\mathbf{Y}}
\end{split}\]</div>
<p>These equations produce the <em>predicted</em> values from the model <span class="math notranslate nohighlight">\(\left(\hat{\mathbf{Y}}\right)\)</span>. As such, another way to look at the GLM is as a <em>prediction</em> plus <em>error</em></p>
<div class="math notranslate nohighlight">
\[
\underset{\text{Data}}{\mathbf{Y}} = \underset{\text{Prediction}}{\hat{\mathbf{Y}}} + \underset{\text{Error}}{\boldsymbol{\epsilon}}
\]</div>
<p>where the nature of the prediction depends upon the form of the design matrix.</p>
</section>
</section>
<section id="building-the-design-matrix">
<h2>Building the Design Matrix<a class="headerlink" href="#building-the-design-matrix" title="Permalink to this heading">#</a></h2>
<p>At the core of the GLM is the structure of the design matrix. This is the part of the GLM that changes from analysis-to-analysis and is the element that defines different models of our data. The <em>general</em> bit of the GLM is a reference to the fact that including continuous predictors in the design matrix will produce a regression model, whereas including categorical predictors will produce an ANOVA model. As we will come to see, the design matrix is such a key part of the GLM that SPM chooses to <em>visualise</em> this element as a means of communicating the form of GLM being used to model the fMRI data. As such, understanding how the design matrix is structured is vital to understanding the GLM.</p>
<section id="continuous-predictor-variables">
<h3>Continuous Predictor Variables<a class="headerlink" href="#continuous-predictor-variables" title="Permalink to this heading">#</a></h3>
<p>Any variable that is <em>numeric</em> and represents some sort of <em>measurement</em> is classified as a <em>continuous</em> predictor variable. For instance, measurements such as IQ, reaction time, test score, age or weight are examples of continuous predictor variables. These types of variables enter the design matrix verbatim as column vectors. As such, they do not require any form of special treatment, as we will see in the worked example later in the lesson.</p>
</section>
<section id="categorical-predictor-variables">
<h3>Categorical Predictor Variables<a class="headerlink" href="#categorical-predictor-variables" title="Permalink to this heading">#</a></h3>
<p>Any variable that represents a form of <em>grouping</em> or <em>category</em> is classified as a <em>categorical</em> variable. For instance, categories such as diagnostic group, blood type or ethnicity are examples of categorical predictor variables. Compared with continuous variables, categorical variables are more complex to use with the GLM. Fundamentally, the category labels must be converted into numbers. The way this is done is by forming what are known as <em>dummy variables</em>. These are variables that conatin either a value of 1 or 0 depending on the category. For instance, if the categories were <em>patient</em> or <em>control</em>, the dummy variable values could be assigned like so</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Category</p></th>
<th class="head"><p>Dummy Variable Value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Control</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>Patient</p></td>
<td><p>1</p></td>
</tr>
</tbody>
</table>
</div>
<p>If there is a variable with more than two categories, more than one dummy variable can be used</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Blood Type</p></th>
<th class="head"><p>Dummy 1 Value</p></th>
<th class="head"><p>Dummy 2 Value</p></th>
<th class="head text-right"><p>Dummy 3 Value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>A</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td class="text-right"><p>0</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>B</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td class="text-right"><p>0</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>AB</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td class="text-right"><p>1</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>O</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td class="text-right"><p>0</p></td>
</tr>
</tbody>
</table>
</div>
<p>In both cases, notice how there is always one fewer dummy variable than the number of categories. As an illustration, consider the design matrix below containing a dummy variable representing diagnosis, where the first 3 subjects are patients and the last 3 are controls.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{X} = 
\begin{bmatrix}
1 &amp; 1 \\
1 &amp; 1 \\
1 &amp; 1 \\
1 &amp; 0 \\
1 &amp; 0 \\
1 &amp; 0
\end{bmatrix}
\end{split}\]</div>
</section>
</section>
<section id="estimating-the-parameters">
<h2>Estimating the Parameters<a class="headerlink" href="#estimating-the-parameters" title="Permalink to this heading">#</a></h2>
<p>Once the design matrix is formed, the probability model of the GLM is given by</p>
<div class="math notranslate nohighlight">
\[
\mathbf{Y}_{i} \sim \mathcal{N}\left(\mathbf{X}_{i}\boldsymbol{\beta},\sigma\right)
\]</div>
<p>The next step is therefore to use maximum likelihood methods to estimate the parameters. Although beyond the scope of this lesson to discuss in more detail, maximum likelihood can be used to derive a single equation that estimates the regression plane that best fits the data. In this context, “best fits” is equivalent to minimising the errors, such that the estimated parameters are those that minimises the vertical distances between the regression plane and the raw data. The equation that achieves this is given by</p>
<div class="math notranslate nohighlight">
\[
\hat{\boldsymbol{\beta}} = \left(\mathbf{X}^{\prime}\mathbf{X}\right)^{-1}\mathbf{X}^{\prime}\mathbf{Y}
\]</div>
<p>which is notable for its reliance on a matrix <em>inverse</em>. Recall that not all matrices are invertible, meaning that not every model specified in the design matrix will be estimable. This is more of an issue with other fMRI software, but is rarely a problem with SPM given its use of a <em>pseudo-inverse</em> for solving this equation. This approach comes with its own limitations, but does mean that all models should be estimable and we are not limited in terms of the form that the design matrix can take.</p>
<p>Once the value of <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> is determined, the value of <span class="math notranslate nohighlight">\(\sigma\)</span> can be derived from the errors. The error vector <span class="math notranslate nohighlight">\(\boldsymbol{\epsilon}\)</span> is formed by a simple subtraction</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\epsilon} = \mathbf{Y} - \mathbf{X}\hat{\boldsymbol{\beta}}
\]</div>
<p>and can then be used to derive the model variance using</p>
<div class="math notranslate nohighlight">
\[
\hat{\sigma}^{2} = \frac{\boldsymbol{\epsilon}^{\prime}\boldsymbol{\epsilon}}{n-k}
\]</div>
<p>This is simply the sum of squared errors, the square-root of which provides the estimate of the standard deviation of the probability model distribution.</p>
</section>
<section id="interpreting-the-parameters">
<h2>Interpreting the Parameters<a class="headerlink" href="#interpreting-the-parameters" title="Permalink to this heading">#</a></h2>
<p>Once the parameters have been estimated, interest turns to interpreting what they <em>mean</em>. Remembering that the parameters represent summaries of the effects and relationships in the dataset, knowing how to interpret their value is of important in order to reach conclusions about the phenomena of interest.</p>
<section id="parameter-estimates-for-continuous-predictors">
<h3>Parameter Estimates for Continuous Predictors<a class="headerlink" href="#parameter-estimates-for-continuous-predictors" title="Permalink to this heading">#</a></h3>
<p>If the variable associated with a parameter estimate is continuous, the parameter is interpreted as the value as a <em>regression slope</em>. For a unit change in the predictor variable, the parameter indicates how much the outcome variable is predicted to change. For example, a model containing a continuous predictor with a parameter estimate of <span class="math notranslate nohighlight">\(\hat{\beta}_{1} = -5.344\)</span> is visualised in <a class="reference internal" href="#continuous-fig"><span class="std std-numref">Fig. 7</span></a>. This would be interpreted as the outcome variable decreasing by 5.344 for each unit increase of the predictor.</p>
<figure class="align-default" id="continuous-fig">
<a class="reference internal image-reference" href="_images/reg-continuous.png"><img alt="_images/reg-continuous.png" src="_images/reg-continuous.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 7 </span><span class="caption-text">Example of the regression slope associated with a continuous predictor variable and a parameter estimate of <span class="math notranslate nohighlight">\(\beta_{1}=-5.344\)</span>.</span><a class="headerlink" href="#continuous-fig" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="parameter-estimates-for-categorical-predictors">
<h3>Parameter Estimates for Categorical Predictors<a class="headerlink" href="#parameter-estimates-for-categorical-predictors" title="Permalink to this heading">#</a></h3>
<p>If the variable associated with a parameter estimate is categorical, the parameter would be interpreted as a <em>mean difference</em>. To see why, consider what happens when we fit a regression slope to a dummy variable, as shown in <a class="reference internal" href="#dummy-fig"><span class="std std-numref">Fig. 8</span></a>. Notice how the slope begins at the mean of the group coded with a 0 and then ends at the mean of the group coded with a 1. A unit increase on a dummy variable is equivalent to changing the category from 0 to 1. This means that the regression slope is still interpreted in the same fashion as before, but in this context tells us the <em>mean difference</em> between the categories. The <em>intercept</em> of this model is therefore the mean of the group coded as 0, the slope is the mean difference and the sum of the intercept and slope gives the mean of the group coded as 1.</p>
<figure class="align-default" id="dummy-fig">
<a class="reference internal image-reference" href="_images/reg-dummy.png"><img alt="_images/reg-dummy.png" src="_images/reg-dummy.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 8 </span><span class="caption-text">Example of the regression slope associated with a categorical predictor variable and a parameter estimate of <span class="math notranslate nohighlight">\(\beta_{1}=7.940\)</span>.</span><a class="headerlink" href="#dummy-fig" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="standard-errors-of-the-estimates">
<h3>Standard Errors of the Estimates<a class="headerlink" href="#standard-errors-of-the-estimates" title="Permalink to this heading">#</a></h3>
<p>Although the values of the parameter estimates can be interpreted on their own, to perform statistical inference we also need some indication of how <em>variable</em> the estimates are. This is done by calculating the <em>standard error</em> for each parameter. In the GLM, the standard errors of the parameter estimates can be calculated by first constructing the <em>variance-covariance</em> matrix of the estimates</p>
<div class="math notranslate nohighlight">
\[
\text{Cov}\left(\hat{\boldsymbol{\beta}}\right) = \hat{\sigma}^{2}\left(\mathbf{X}^{\prime}\mathbf{X}\right)^{-1}
\]</div>
<p>This is akin to a correlation matrix, with the variance of each estimate on the diagonal and the correlation (covariance) between the estimates on the off-diagonal. The standard errors can then be taken as the square-root of the diagonal elements of <span class="math notranslate nohighlight">\(\text{Cov}\left(\hat{\boldsymbol{\beta}}\right)\)</span>.</p>
</section>
<section id="inference">
<h3>Inference<a class="headerlink" href="#inference" title="Permalink to this heading">#</a></h3>
<p>The final step in using the GLM framework is to perform some sort of hypothesis test using the estimated parameter values. Typically, each estimate will be divided by its standard error to produce a <em>t</em>-statistics. For instance</p>
<div class="math notranslate nohighlight">
\[
t = \frac{\hat{\beta}_{1}}{\text{SE}\left\{\hat{\beta}_{1}\right\}}
\]</div>
<p>This particular test statistic involves an implicit comparison of <span class="math notranslate nohighlight">\(\hat{\beta}_{1}\)</span> with a proposed population value of <span class="math notranslate nohighlight">\(\beta_{1} = 0\)</span>. In the context of a regression slope, the null hypothesis is therefore that there is no relationship between the outcome and predictor (i.e. the slope is <em>flat</em>). In the context of a mean difference, the null hypothesis is that there is no difference in the average value of the outcome variable between the groups (i.e. the means are <em>identical</em>). Decisions about whether the null hypothesis can be rejected can be taken by calculating the <em>p</em>-value associated with the calculated <em>t</em>-statistic via reference to the appropriate null distribution. As such, this element of the GLM is equivalent to performing inference on the results of both the simple and multiple regression models discussed earlier.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "jupyter_matlab_kernel"
        },
        kernelOptions: {
            name: "jupyter_matlab_kernel",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'jupyter_matlab_kernel'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="1.need-for-modelling.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">The Need for Statistical Modelling</p>
      </div>
    </a>
    <a class="right-next"
       href="3.glm-example.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">The GLM: A Worked Example</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-general-linear-model-framework">The General Linear Model Framework</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-regression">Simple Regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-regression">Multiple Regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-regression-in-matrix-form">Multiple Regression in Matrix Form</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-the-design-matrix">Building the Design Matrix</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#continuous-predictor-variables">Continuous Predictor Variables</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#categorical-predictor-variables">Categorical Predictor Variables</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-the-parameters">Estimating the Parameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-the-parameters">Interpreting the Parameters</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parameter-estimates-for-continuous-predictors">Parameter Estimates for Continuous Predictors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#parameter-estimates-for-categorical-predictors">Parameter Estimates for Categorical Predictors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#standard-errors-of-the-estimates">Standard Errors of the Estimates</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inference">Inference</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr Martyn McFarquhar
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>