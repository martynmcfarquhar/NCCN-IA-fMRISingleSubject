

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>The General Linear Model &#8212; fMRI Single-subject Statistical Modelling</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6" />
  <script src="_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=365ca57ee442770a23c6"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '2.glm';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="The GLM: A Worked Example" href="3.glm-example.html" />
    <link rel="prev" title="The Need for Statistical Modelling" href="1.need-for-modelling.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="0.intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="fMRI Single-subject Statistical Modelling - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="fMRI Single-subject Statistical Modelling - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="0.intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="1.need-for-modelling.html">The Need for Statistical Modelling</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">The General Linear Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="3.glm-example.html">The GLM: A Worked Example</a></li>
<li class="toctree-l1"><a class="reference internal" href="4.glm-fmri.html">Using the GLM to Model fMRI Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="5.glm-fmri-problems.html">Problems With Using the GLM to Model fMRI Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="6.single-subject-spm.html">Single-subject Modelling in SPM</a></li>
<li class="toctree-l1"><a class="reference internal" href="7.summary-quiz.html">Summary and Quiz</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/martynmcfarquhar/NCCN-IA-fMRIPreProcessing" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/martynmcfarquhar/NCCN-IA-fMRIPreProcessing/issues/new?title=Issue%20on%20page%20%2F2.glm.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/2.glm.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>The General Linear Model</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-general-linear-model-framework">The General Linear Model Framework</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-regression">Simple Regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-regression">Multiple Regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-regression-in-matrix-form">Multiple Regression in Matrix Form</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-the-design-matrix">Building the Design Matrix</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#continuous-predictor-variables">Continuous Predictor Variables</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#categorical-predictor-variables">Categorical Predictor Variables</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-the-parameters">Estimating the Parameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-the-parameters">Interpreting the Parameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference">Inference</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="the-general-linear-model">
<h1>The General Linear Model<a class="headerlink" href="#the-general-linear-model" title="Permalink to this heading">#</a></h1>
<p>To begin with, we will take a high-level perspective on the GLM as a <em>framework</em> that can be applied to any dataset. This may appear somewhat abstract on a first read, however, we will see how this is applied to a real dataset in the next section. Remember that at this point we are not talking about fMRI data specifically. Given that this is a specialised application of the GLM, we first need to discuss the general theory before seeing how this traditional approach needs to be adjusted to suit modelling an fMRI time series.</p>
<section id="the-general-linear-model-framework">
<h2>The General Linear Model Framework<a class="headerlink" href="#the-general-linear-model-framework" title="Permalink to this heading">#</a></h2>
<p>To begin with, we will discuss the mathematical framework behind the GLM. In order to understand the GLM, we need to understand <em>multiple regression</em> which, in its most basic form, is know as <em>simple</em> regression.</p>
<section id="simple-regression">
<h3>Simple Regression<a class="headerlink" href="#simple-regression" title="Permalink to this heading">#</a></h3>
<p>In a simple regression model there is a single outcome variable <span class="math notranslate nohighlight">\(y\)</span> that is associated with a single predictor variable <span class="math notranslate nohighlight">\(x\)</span>. The simple regression model takes the form</p>
<div class="math notranslate nohighlight">
\[
y_{i} = \beta_{0} + \beta_{1}x_{i} + \epsilon_{i}
\]</div>
<p>which defines a straight-line fit to the data, with <span class="math notranslate nohighlight">\(\beta_{0}\)</span> representing the <em>intercept</em> and <span class="math notranslate nohighlight">\(\beta_{1}\)</span> representing the <em>slope</em>. The term <span class="math notranslate nohighlight">\(\epsilon\)</span> quantifies the amount of <em>error</em> in the model, allowing for the fact that a perfect fit between the two variables is rarely possible. This model is illustrated in <a class="reference internal" href="#simple-fig"><span class="std std-numref">Fig. 4</span></a>. In this example, the manager of a production line wants a good estimate of the required number of worker hours given the number of units that must be produced (the <em>lot size</em>).</p>
<figure class="align-default" id="simple-fig">
<a class="reference internal image-reference" href="_images/simple-reg.png"><img alt="_images/simple-reg.png" src="_images/simple-reg.png" style="width: 700px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4 </span><span class="caption-text">Illustration of how a simple regression model amounts to constructing a straight-line to summarise the relationship between the predictor variable and the outcome variable.</span><a class="headerlink" href="#simple-fig" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>As we can see, the simple regression model consists of a straight line through the scatterplot of measurements. For each value of <code class="docutils literal notranslate"><span class="pre">Lot</span> <span class="pre">Size</span></code>, the point on the regression line represents the predicted value of <code class="docutils literal notranslate"><span class="pre">Hours</span></code>. The magnitude of the estimated slope is therefore of interest, given that this quantifies the <em>strength</em> of the general relationship between the two variables. However, we also need to consider how close the raw data sits to the regression line as data that are tightly-packed around the regression line suggest a model that fits the data well. This concept of <em>model fit</em> is therefore quantified by the <em>errors</em>. The smaller that the <span class="math notranslate nohighlight">\(\epsilon\)</span> terms are, the shorter the vertical distances between the regression line and the raw data.</p>
<p>These concepts can be further understood by considering the probability model for a simple regression</p>
<div class="math notranslate nohighlight">
\[
y_{i} \sim \mathcal{N}(\beta_{0} + \beta_{1}x_{i}, \sigma)
\]</div>
<p>Taking the example from <a class="reference internal" href="#simple-fig"><span class="std std-numref">Fig. 4</span></a>, each value of <code class="docutils literal notranslate"><span class="pre">Lot</span> <span class="pre">Size</span></code> is therefore associated with a normal distribution of values for <code class="docutils literal notranslate"><span class="pre">Hours</span></code> where the means sit along the population regression line. An illustration of this concept is given in <a class="reference internal" href="#simple-prob-fig"><span class="std std-numref">Fig. 5</span></a>.</p>
<figure class="align-default" id="simple-prob-fig">
<a class="reference internal image-reference" href="_images/simple-reg-prob.gif"><img alt="_images/simple-reg-prob.gif" src="_images/simple-reg-prob.gif" style="width: 700px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 5 </span><span class="caption-text">Illustration of the simple regression normal probability model. The operator <span class="math notranslate nohighlight">\(E(Y)\)</span> indicates the <em>expected</em> value of the outcome variable which, for a normal distribution, is equivalent to the mean.</span><a class="headerlink" href="#simple-prob-fig" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>The standard deviation of these normal distributions is given by <span class="math notranslate nohighlight">\(\sigma\)</span> and reflects how widely spread the data are around the regression line. There is therefore a direct connection between the width of the assumed probability distributions and the model errors. As such, for each value of <code class="docutils literal notranslate"><span class="pre">Lot</span> <span class="pre">Size</span></code>, we expect there to be a normal distribution of errors, spread equally above and below the line, with most errors close to the line and fewer further away. As such, the simple regression model can also be expressed as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
y_{i} &amp;= \beta_{0} + \beta_{1}x_{i} + \epsilon_{i} \\
\epsilon_{i} &amp;\sim \mathcal{N}(0,\sigma)
\end{align}
\end{split}\]</div>
<p>Remembering that this probability model represents the <em>population</em>, the aim of a simple regression analysis is to use a <em>sample</em> to estimate both the <em>mean</em> and <em>variance</em> of the population distribution. As the mean depends upon the parameters <span class="math notranslate nohighlight">\(\beta_{0}\)</span> and <span class="math notranslate nohighlight">\(\beta_{1}\)</span>, these must also be estimated from the sample. Finding the line that best fits the data will result in estimates for <span class="math notranslate nohighlight">\(\beta_{0}\)</span> and <span class="math notranslate nohighlight">\(\beta_{1}\)</span>. The errors resulting from this fit can then be used to estimate <span class="math notranslate nohighlight">\(\sigma\)</span>.</p>
<p>Once the parameters are estimated, hypothesis testing can be used to determine whether the null hypotheses</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathcal{H}_{0}:&amp; \beta_{0} = 0 \\
\mathcal{H}_{0}:&amp; \beta_{1} = 0
\end{align}
\end{split}\]</div>
<p>can be rejected. Usually, the test on <span class="math notranslate nohighlight">\(\beta_{1}\)</span> is of most interest because a slope of 0 is indicative of <em>no</em> relationship between the outcome and predictor variables. If significant, we would assume some non-zero relationship is present in the population and can interpret what the magnitude of <span class="math notranslate nohighlight">\(\hat{\beta}_{1}\)</span> tells us about the relationship under study. This is often in the context of using the simple regression model to <em>predict</em> the outcome using the values of the predictor. For the example above, this would result in being able to predict <code class="docutils literal notranslate"><span class="pre">Hours</span></code> by only knowing the value of <code class="docutils literal notranslate"><span class="pre">Lot</span> <span class="pre">Size</span></code>, allowing the manager to determine if more or fewer workers need to be hired as production demands are scaled up or down.</p>
<div class="tip admonition">
<p class="admonition-title">Randomness of the errors</p>
<p>One of the more confusing aspects of statistical models is that they can be written in mutliple equivalent ways. For instance, for simple regression, the probability model can be written as either</p>
<div class="math notranslate nohighlight">
\[
y_{i} \sim \mathcal{N}\left(\beta_{0} + \beta_{1}x_{i},\sigma\right)
\]</div>
<p>or</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
y_{i} &amp;= \beta_{0} + \beta_{1}x_{i} + \epsilon_{i} \\
\epsilon_{i} &amp;\sim \mathcal{N}(0,\sigma)
\end{align}
\end{split}\]</div>
<p>Although the first form may be more intuitive, the second form is insightful in terms of the principles of these models. Recall that we are assuming that there is some <em>constant</em> effect that runs through all our observations of a particular phenomena. Also recall that we assume that the reason we do not observe the same value every time is because we are measuring a <em>random process</em> that is subject to measurement error. As such, each measurement we take is the sum of our constant effect of interest and random perturbations. This structure is then reflected in the statistical model, as the mean of the assumed distribution is considered the <em>constant</em> effect and the errors are considered the <em>random</em> deflections. As such, the <em>errors</em> are the element that creates randomness and thus are the <em>random variable</em> component of our measurements. In statistical parlance, this is the distinction between <em>fixed-effects</em> and <em>random-effects</em>. Fixed-effects are associated with the mean of the assumed probability distribution, whereas random-effects are associated with random perturbations and thus the <em>variance</em> of the measurements.</p>
</div>
</section>
<section id="multiple-regression">
<h3>Multiple Regression<a class="headerlink" href="#multiple-regression" title="Permalink to this heading">#</a></h3>
<p>Expanding the simple regression model to contain <em>multiple</em> predictor variables produces the multiple regression model. As such, the multiple regression model with <span class="math notranslate nohighlight">\(k\)</span> predictor variables is given by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
y_{i} &amp;= \beta_{0} + \beta_{1}x_{i1} + \beta_{2}x_{i2} + \dots + \beta_{k}x_{ik} + \epsilon_{i} \\
&amp;= \beta_{0} + \sum_{j=1}^{k} \beta_{j}x_{ij} + \epsilon_{i}
\end{align}
\end{split}\]</div>
<p>where we usually assume a normal probability model of the form</p>
<div class="math notranslate nohighlight">
\[
y_{i} \sim \mathcal{N}\left(\beta_{0} + \sum_{j=1}^{k} \beta_{j}x_{ij},\sigma\right)
\]</div>
<p>which can also be expressed as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
y_{i} &amp;= \beta_{0} + \sum_{j=1}^{k} \beta_{j}x_{ij} + \epsilon_{i} \\
\epsilon_{i} &amp;\sim \mathcal{N}\left(0,\sigma\right)
\end{align}
\end{split}\]</div>
<p>Conceptually, much of multiple regression is the same as simple regression, except for a few details. Firstly, rather than a regression line this model estimates a regression <em>plane</em> in <span class="math notranslate nohighlight">\(k\)</span>-dimensional space. For instance, if <span class="math notranslate nohighlight">\(k=2\)</span> then the model can be visualised as shown in <a class="reference internal" href="#plane-fig"><span class="std std-numref">Fig. 6</span></a></p>
<figure class="align-default" id="plane-fig">
<a class="reference internal image-reference" href="_images/reg-plane.png"><img alt="_images/reg-plane.png" src="_images/reg-plane.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 6 </span><span class="caption-text">Illustration of how a multiple regression model with <span class="math notranslate nohighlight">\(k\)</span> predictors forms a regression <em>plane</em> through <span class="math notranslate nohighlight">\(k\)</span>-dimensional space.</span><a class="headerlink" href="#plane-fig" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>The means of the assumed normal distributions are no longer points along a regression line, rather they become points on a plane in <span class="math notranslate nohighlight">\(k\)</span>-dimensional space. The individual regression slopes for each predictor <span class="math notranslate nohighlight">\(\left(\beta_{j}\right)\)</span> are given by the <em>edges</em> of this plane (where <span class="math notranslate nohighlight">\(j = 1,\dots,k\)</span>). Importantly, these slopes are not the same as fitting a simple regression model to each predictor separately. The slope coefficients represent the effect of each predictor after taking all other predictors into account. This means that adding or altering the predictors will change <em>all</em> the parameter estimates. This is an important point because many statistical modelling decisions are built upon this fact. For instance, the notion of <em>controlling</em> for the effect of a variable is based directly upon this behaviour.</p>
<p>Despite these differences, the multiple regression model proceeds in much the same fashion as simple regression. The individual parameters of the mean function can be estimated to produce a single estimate for the intercept <span class="math notranslate nohighlight">\(\left(\beta_{0}\right)\)</span> and <span class="math notranslate nohighlight">\(k\)</span> estimates for the slopes <span class="math notranslate nohighlight">\(\left(\beta_{1},\dots,\beta_{k}\right)\)</span>. Estimation of the variance again proceeds using the errors, which now represent vertical distances from the regression <em>plane</em> to the raw data. Hypothesis tests can then be performed on each of the estimates to determine which of the <span class="math notranslate nohighlight">\(k\)</span> variables appears to show a significant non-zero relationship with the outcome. This involves testing null hypotheses of the form</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathcal{H}_{0}:&amp; \beta_{0} = 0 \\
\mathcal{H}_{0}:&amp; \beta_{1} = 0 \\
\vdots \\
\mathcal{H}_{0}:&amp; \beta_{k} = 0
\end{align}
\end{split}\]</div>
<p>Much like simple regression, the general aim is the accurate <em>prediction</em> of the outcome, this time using value of <em>multiple</em> variables. For instance, the manager of the production line may enhance their model of <code class="docutils literal notranslate"><span class="pre">Hours</span></code> by also considering <code class="docutils literal notranslate"><span class="pre">Wage</span></code> and <code class="docutils literal notranslate"><span class="pre">Age</span></code> of the workers, alongside <code class="docutils literal notranslate"><span class="pre">Lot</span> <span class="pre">Size</span></code>. This may allow for a more accurate prediction of <code class="docutils literal notranslate"><span class="pre">Hours</span></code>, as well as allowing the manager to determine which factor is the most influential and where the focus should be when considering how to adapt to changes in production.</p>
</section>
<section id="multiple-regression-in-matrix-form">
<h3>Multiple Regression in Matrix Form<a class="headerlink" href="#multiple-regression-in-matrix-form" title="Permalink to this heading">#</a></h3>
<p>Now that we have discussed both <em>simple</em> and <em>multiple</em> regression, we can return to the topic of the GLM. The most important point to understand is that the GLM is simply <em>multiple regression in matrix form</em>. As such, if you understand multiple regression, then you already understand the GLM. The fact that there is a different term to refer to the matrix-variant of multiple regression is largely historical, as discussed in the box below.</p>
<div class="tip admonition">
<p class="admonition-title">The history of the GLM</p>
<p>Historically, statistical analyses could be categorised as either <em>regression</em> methods or <em>analysis of variance</em> (ANOVA) methods. The distinction was that regression models sought to estimate the relationships between mutliple continuous measurements as a means of prediction, whereas ANOVA models sought to investigate group differences resulting from experimental manipulations. As such, regression was more related to observational studies, whereas ANOVA was associated with designed experiments. However, it was recognised in the 1950s that these two methods could be combined, meaning that an ANOVA model could be specified using mutliple regression. Since this point, the equivelance of these methods has been well-recognised, though regression and ANOVA are still often taught in isolation. The use of the term <em>General Linear Model</em> is usually reserved for the specific matrix-based framework using to specify both regression and ANOVA models, whereas the terms <em>regression</em> and <em>ANOVA</em> are typically used in reference to the more historical non-matrix forms of the same analyses.</p>
</div>
<p>In terms of writing multiple regression in matrix notation, we start with the observation that there are always <span class="math notranslate nohighlight">\(n\)</span> regression equations, one for each data point</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
y_{1} &amp;= \beta_{0} + \beta_{1}x_{11} + \beta_{2}x_{12} + \dots + \beta_{k}x_{1k} + \epsilon_{1} \\
y_{2} &amp;= \beta_{0} + \beta_{1}x_{21} + \beta_{2}x_{22} + \dots + \beta_{k}x_{2k} + \epsilon_{2} \\
y_{3} &amp;= \beta_{0} + \beta_{1}x_{31} + \beta_{2}x_{32} + \dots + \beta_{k}x_{3k} + \epsilon_{3} \\
\vdots  \\
y_{n} &amp;= \beta_{0} + \beta_{1}x_{n1} + \beta_{2}x_{n2} + \dots + \beta_{k}x_{nk} + \epsilon_{n}
\end{align}
\end{split}\]</div>
<p>Because these regression equations represent a system of linear equations, we know we can write them as vectors and matrices. Importantly, we can separate the predictor variables from the coefficients to give the following structure</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{bmatrix}
y_{1} \\
y_{2} \\
y_{3} \\
\vdots \\
y_{n}
\end{bmatrix}
=
\begin{bmatrix}
1      &amp; x_{11} &amp; x_{12}  &amp; \dots  &amp; x_{1k} \\
1      &amp; x_{21} &amp; x_{22}  &amp; \dots  &amp; x_{2k} \\
1      &amp; x_{31} &amp; x_{32}  &amp; \dots  &amp; x_{3k} \\
\vdots &amp; \vdots &amp; \vdots  &amp; \ddots &amp; \vdots \\
1      &amp; x_{n1} &amp; x_{n2}  &amp; \dots  &amp; x_{nk} 
\end{bmatrix}
\begin{bmatrix}
\beta_{0} \\
\beta_{1} \\
\beta_{2} \\
\vdots    \\
\beta_{k}
\end{bmatrix}
+
\begin{bmatrix}
\epsilon_{1} \\
\epsilon_{2} \\
\epsilon_{3} \\
\vdots       \\
\epsilon_{n}
\end{bmatrix}
\end{split}\]</div>
<p>which we can write shorthand as</p>
<div class="math notranslate nohighlight">
\[
\mathbf{Y} = \mathbf{X}\boldsymbol{\beta} + \boldsymbol{\epsilon}
\]</div>
<p>This is probably the most important equation you will see on this course. It encapsulates the entire structure of our data analysis and is something you will become intimately familiar with during this module. To make this structure clear</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{Y}\)</span> represents the <em>data vector</em> containing the values of the outcome variable</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{X}\)</span> represents the <em>design matrix</em> containing each of the predictor variables as columns</p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> represents the vector of <em>model parameters</em></p></li>
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\epsilon}\)</span> represents the vector of <em>errors</em></p></li>
</ul>
<p>Importantly, we need to recognise how multiplying <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> recreates the <span class="math notranslate nohighlight">\(n\)</span> regression equations.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\hat{\mathbf{Y}} = \mathbf{X}\boldsymbol{\beta} = 
\begin{bmatrix}
1      &amp; x_{11} &amp; x_{12}  &amp; \dots  &amp; x_{1k} \\
1      &amp; x_{21} &amp; x_{22}  &amp; \dots  &amp; x_{2k} \\
1      &amp; x_{31} &amp; x_{32}  &amp; \dots  &amp; x_{3k} \\
\vdots &amp; \vdots &amp; \vdots  &amp; \ddots &amp; \vdots \\
1      &amp; x_{n1} &amp; x_{n2}  &amp; \dots  &amp; x_{nk} 
\end{bmatrix}
\begin{bmatrix}
\beta_{0} \\
\beta_{1} \\
\beta_{2} \\
\vdots    \\
\beta_{k}
\end{bmatrix}
=
\begin{bmatrix}
\beta_{0} + \beta_{1}x_{11} + \beta_{2}x_{12} + \dots  + \beta_{k}x_{1k} \\
\beta_{0} + \beta_{1}x_{21} + \beta_{2}x_{22} + \dots  + \beta_{k}x_{2k} \\
\beta_{0} + \beta_{1}x_{31} + \beta_{2}x_{32} + \dots  + \beta_{k}x_{3k} \\
\vdots  \\
\beta_{0} + \beta_{1}x_{n1} + \beta_{2}x_{n2} + \dots  + \beta_{k}x_{nk}
\end{bmatrix}
\end{split}\]</div>
<p>These equations produce the <em>predicted</em> values from the model <span class="math notranslate nohighlight">\(\left(\hat{\mathbf{Y}}\right\)</span>. As such, another way to look at the GLM is as a <em>prediction</em> plus <em>error</em></p>
<div class="math notranslate nohighlight">
\[
\underset{\text{Data}}{\mathbf{Y}} = \underset{\text{Prediction}}{\hat{\mathbf{Y}}} + \underset{\text{Error}}{\boldsymbol{\epsilon}}
\]</div>
</section>
</section>
<section id="building-the-design-matrix">
<h2>Building the Design Matrix<a class="headerlink" href="#building-the-design-matrix" title="Permalink to this heading">#</a></h2>
<p>At the core of the GLM is the structure of the design matrix. This is the part of the GLM that changes from analysis-to-analysis and is the part that defines different models of our data. In fact the general bit of the GLM is a reference to its ability to accommodate different analyses, simply through the specification of different design matrices. As we will come to see, SPM visualises the design matrix for us as a means of communicating the model that we are fitting to our data. This is an indication of how important this part of the GLM is and thus it is important to understand how we can structure it to accommodate different types of predictor variables.</p>
<section id="continuous-predictor-variables">
<h3>Continuous Predictor Variables<a class="headerlink" href="#continuous-predictor-variables" title="Permalink to this heading">#</a></h3>
<p>Any variable that is numeric and represents some sort of measurement is classified as a continuous predictor variable. This includes any quantifiable phenomena such as IQ, reaction time, score on a test, age, weight etc. These types of predictor variables are straightforward to use within the GLM because we simply add them verbatim to the design matrix as columns. As such, they do not require any form of special treatment to be used. We will see examples of these types of variables in the next section, when we look at an example GLM using some real-world data.</p>
</section>
<section id="categorical-predictor-variables">
<h3>Categorical Predictor Variables<a class="headerlink" href="#categorical-predictor-variables" title="Permalink to this heading">#</a></h3>
<p>Any variable that represents a form of grouping or category is classified as a categorical variable. This could include variables such as sex, patient group, blood type, ethnicity etc. Compared with continuous variables, categorical predictor variables are more complex to use with the GLM. Fundamentally, what we have to do is to turn these categories into numbers in order to put them in the design matrix. The way we do this is to form dummy variables. These are variables that have a value of 1 or 0 depending on the category. For instance, if the categories were male or female, we could assign values like so</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Category</p></th>
<th class="head"><p>Dummy Variable Value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Control</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>Patient</p></td>
<td><p>1</p></td>
</tr>
</tbody>
</table>
<p>If we have a variable with more than two categories, we can include more dummy variables like so</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Blood Type</p></th>
<th class="head"><p>Dummy 1 Value</p></th>
<th class="head"><p>Dummy 2 Value</p></th>
<th class="head text-right"><p>Dummy 3 Value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p>A</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td class="text-right"><p>0</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>B</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td class="text-right"><p>0</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>AB</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td class="text-right"><p>1</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>O</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td class="text-right"><p>0</p></td>
</tr>
</tbody>
</table>
<p>Notice how we always have one fewer dummy variable than the number of categories. So we only need 1 dummy variable to represent the 2 categories of male or female, and we only need 3 dummy variables to represent the 4 categories of blood type. As an example, we can see a design matrix below that contains a dummy variable representing diagnosis, where the first 3 subjects are patients and the last 3 are controls.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{X} = 
\begin{bmatrix}
1 &amp; 1 \\
1 &amp; 1 \\
1 &amp; 1 \\
1 &amp; 0 \\
1 &amp; 0 \\
1 &amp; 0
\end{bmatrix}
\end{split}\]</div>
<p>Any row that contains a 1 in the second column indicates that subject is female whereas any row that contains a 0 in the second column indicates that subject is male. We are going to see dummy variables used a lot and so do not worry if this concept is not clear yet. We will see plenty of examples as we press forward.</p>
</section>
</section>
<section id="estimating-the-parameters">
<h2>Estimating the Parameters<a class="headerlink" href="#estimating-the-parameters" title="Permalink to this heading">#</a></h2>
<p>Once we have constructed our design matrix, we have a fully-formed probability model of the form</p>
<div class="math notranslate nohighlight">
\[
\mathbf{Y} \sim \mathcal{N}\left(\mathbf{X}\boldsymbol{\beta},\sigma\mathbf{I}\right)
\]</div>
<p>The next step is therefore to use maximum likelihood methods to estimate the model parameters. The equations that are derived from the method of maximum likelihood can be written in matrix terms to give a single equation that will simultaneously estimate values for every parameter. This equation is given by</p>
<div class="math notranslate nohighlight">
\[
\hat{\boldsymbol{\beta}} = \left(\mathbf{X}^{\prime}\mathbf{X}\right)^{-1}\mathbf{X}^{\prime}\mathbf{Y}
\]</div>
<p>and is notable for its use of a matrix inverse. As you may remember from the Computational Tools lesson in Functional Neuroanatomy, inverting a matrix is a tricky business because an inverse may not always exist. This tells us something about the limitations of the GLM, namely that not every model we may want to use will be estimable. This is a thorny issue, but one which is thankfully rarely a concern when using SPM.</p>
</section>
<section id="interpreting-the-parameters">
<h2>Interpreting the Parameters<a class="headerlink" href="#interpreting-the-parameters" title="Permalink to this heading">#</a></h2>
<p>Once we have the parameter estimates, our aim is to try and interpret what they mean, given that their values represents important summaries of the effects in our dataset. If the variable associated with a parameter estimate is a continuous variable, we would interpret the value as a regression slope, telling us how much our outcome variable is predicted to change for a unit increase in the predictor variable. For example, a regression slope with a value of -5.344 is visualised in <a class="reference internal" href="#continuous-fig"><span class="std std-numref">Fig. 7</span></a></p>
<figure class="align-default" id="continuous-fig">
<a class="reference internal image-reference" href="_images/reg-continuous.png"><img alt="_images/reg-continuous.png" src="_images/reg-continuous.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 7 </span><span class="caption-text">Example of the regression slope associated with a continuous predictor variable and a parameter estimate of <span class="math notranslate nohighlight">\(\beta_{1}=-5.344\)</span>.</span><a class="headerlink" href="#continuous-fig" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>This can be interpreted as a unit increase in the value of the predictor variable being associated with a decrease in the value of the outcome variable of 5.344. By comparison, if the variable associated with a parameter estimate is a categorical variable, we would interpret the value as a mean difference. To see why, consider what happens when we fit a regression slope to a dummy variable with a value of 0 or 1</p>
<figure class="align-default" id="dummy-fig">
<a class="reference internal image-reference" href="_images/reg-dummy.png"><img alt="_images/reg-dummy.png" src="_images/reg-dummy.png" style="width: 500px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 8 </span><span class="caption-text">Example of the regression slope associated with a categorical predictor variable and a parameter estimate of <span class="math notranslate nohighlight">\(\beta_{1}=7.940\)</span>.</span><a class="headerlink" href="#dummy-fig" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>So we can see that the model is still fitting a regression slope, but one that goes from the mean of one category to the mean of the other. In this example, the slope has a value of 7.94 which tells us the mean difference between the categories. The intercept of the model is the mean of the group coded as 0 and a unit change simply refers to the change from one group to the other. So although this is still the same interpretation as any other regression slope, it is useful to think of the slopes from dummy variables representing mean differences.</p>
<p>Although we can interpret the values of our parameter estimates, on their own this not enough because we also need to know how much we can trust these estimates. This is done by calculating the standard deviation of the sampling distribution of the estimates, known as the standard error. In the GLM, the standard errors of the parameter estimates can be calculated using the estimate of the model variance</p>
<div class="math notranslate nohighlight">
\[
\hat{\sigma}^{2} = \frac{\boldsymbol{\epsilon}^{\prime}\boldsymbol{\epsilon}}{n-p}
\]</div>
<p>which is the squared estimate of the standard deviation of the normal distribution we are using for our model. Here, n is the number of rows of X and p is the number of model parameters (the number of columns of X). This is then combined with the design matrix to produce a variance-covariance matrix</p>
<div class="math notranslate nohighlight">
\[
\text{Cov}\left(\hat{\boldsymbol{\beta}}\right) = \hat{\sigma}^{2}\left(\mathbf{X}^{\prime}\mathbf{X}\right)^{-1}
\]</div>
<p>You do not need to worry too much about what this represents. The main point is just that the standard errors are taken as the square-root of the diagonal elements of this matrix.</p>
</section>
<section id="inference">
<h2>Inference<a class="headerlink" href="#inference" title="Permalink to this heading">#</a></h2>
<p>… Although this seems fairly straightforward, inference using neuroimaging data has some very specific challenges that we will pick up on next week.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "jupyter_matlab_kernel"
        },
        kernelOptions: {
            name: "jupyter_matlab_kernel",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'jupyter_matlab_kernel'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="1.need-for-modelling.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">The Need for Statistical Modelling</p>
      </div>
    </a>
    <a class="right-next"
       href="3.glm-example.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">The GLM: A Worked Example</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-general-linear-model-framework">The General Linear Model Framework</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#simple-regression">Simple Regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-regression">Multiple Regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-regression-in-matrix-form">Multiple Regression in Matrix Form</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#building-the-design-matrix">Building the Design Matrix</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#continuous-predictor-variables">Continuous Predictor Variables</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#categorical-predictor-variables">Categorical Predictor Variables</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#estimating-the-parameters">Estimating the Parameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpreting-the-parameters">Interpreting the Parameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference">Inference</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dr Martyn McFarquhar
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>